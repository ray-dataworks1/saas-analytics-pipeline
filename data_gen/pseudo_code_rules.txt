data_generation_rules:
  - name : "Data Skewness"
    description: "Generate a dataset where the top 5% of organisations account for 50% of the total orders."
    justification: "This rule is designed to create a dataset that reflext real world scenarios where oligopsony conditions in B2B firms persist - in this case, SaaS."
    implementation:
      - "Generate a list of organisations with varying sizes."
      - "Assign order values to each organisation such that the top 5% of organisations have significantly higher order values compared to the rest."
      - "Ensure that the total order value from the top 5% of organisations equals 50% of the overall total order value."
      - "Use a random distribution to assign order values to the remaining 95% of organisations, ensuring a realistic spread of order values."
      - "Validate the dataset to confirm that the skewness condition is met."
  - name : "Late Arriving Orders"
    description: "Create a dataset that includes late arriving orders to simulate real-world scenarios where orders may be delayed."
    justification: "This rule is intended to mimic real-world situations where orders may not arrive on time, affecting inventory and supply chain management."
    implementation:
      - "Generate a list of orders with expected delivery dates."
      - "Randomly select a percentage of orders (e.g., 10-20%) to be marked as late."
      - "For the selected late orders, adjust their delivery dates to be later than the expected dates by a random number of days (e.g., 1-7 days)."
      - "Ensure that the dataset includes both on-time and late orders, with appropriate timestamps for each."
      - "Validate the dataset to confirm that the late arriving orders are correctly marked and that their delivery dates are adjusted accordingly."
  # Additional twist here, could we simulate late orders with no clear documented reason and set up an auditing trail to investigate?
  - name : "Seasonal Demand Fluctuations"
    description: "Generate a dataset that reflects seasonal demand fluctuations for a product or service."
    justification: "This rule aims to create a dataset that captures the impact of seasonal trends on demand, which is crucial for inventory and sales forecasting."
    implementation:
      - "Identify key seasons or periods (e.g., holidays, back-to-school, summer) that typically see increased demand."
      - "Generate a base level of demand for the product or service throughout the year."
      - "Increase the demand levels during the identified key seasons by a significant percentage (e.g., 30-50%)."
      - "Use historical data or industry benchmarks to inform the magnitude of demand increases during these periods."
      - "Validate the dataset to ensure that seasonal fluctuations are accurately represented and that overall demand trends are realistic."
  - name: "Malformed JSON"
    description: "Create a dataset that injects malformed JSON entries 1-2% of the time."
    justification: "This rule is designed to test the robustness of data processing systems by introducing malformed JSON entries, which are common in real-world data scenarios."
    implementation:
      - "Generate a standard dataset with well-formed JSON entries."
      - "Randomly select 1-2% of the entries to be malformed."
      - "Introduce common JSON malformations such as missing commas, unclosed brackets, or incorrect data types."
      - "Ensure that the malformed entries are distributed throughout the dataset to simulate real-world occurrences."
      - "Validate the dataset to confirm that the specified percentage of entries are indeed malformed and that they reflect common JSON errors."
  - name: "Duplicate Entries"
    description: "Create a dataset that includes duplicate entries to simulate real-world data duplication issues." 
    justification: "This rule is intended to mimic real-world scenarios where data duplication can occur due to various reasons, such as system errors or user input mistakes."
    implementation:
      - "Generate a list of unique entries for the dataset."
      - "Randomly select a percentage of entries (e.g., 5-10%) to be duplicated."
      - "Create duplicates of the selected entries and add them back into the dataset."
      - "Ensure that the duplicates are exact copies of the original entries, including all fields and values."
      - "Validate the dataset to confirm that the specified percentage of entries are duplicates and that they are correctly formatted."
  - name: "Missing Values"
    description: "Create a dataset that includes missing values in certain fields to simulate real-world data incompleteness."
    justification: "This rule is designed to reflect real-world scenarios where datasets may have missing values due to various reasons, such as data entry errors or incomplete data collection."
    implementation: 
      - "Generate a complete dataset with all fields populated."
      - "Randomly select a percentage of entries (e.g., 5-15%) to have missing values in specific fields."
      - "Remove the values from the selected fields for the chosen entries, ensuring that the missing values are distributed throughout the dataset."
      - "Ensure that the missing values are realistic and reflect common scenarios, such as missing customer names or order amounts."
      - "Validate the dataset to confirm that the specified percentage of entries have missing values and that they are correctly represented as null or empty."
  - name: "Inconsistent Data Formats"
    description: "Create a dataset that includes inconsistent data formats to simulate real-world data variability."
    justification: "This rule aims to reflect real-world scenarios where data may be recorded in different formats due to varying data sources or user inputs."
    implementation:
      - "Generate a dataset with consistent data formats for all fields."
      - "Randomly select a percentage of entries (e.g., 5-10%) to have inconsistent data formats in specific fields."
      - "Alter the data formats for the selected entries, such as changing date formats (e.g., MM/DD/YYYY to DD-MM-YYYY) or number formats (e.g., using commas vs. periods as decimal separators)."
      - "Ensure that the inconsistent formats are realistic and reflect common variations seen in real-world data."
      - "Validate the dataset to confirm that the specified percentage of entries have inconsistent data formats and that they are correctly represented."
  - name: "Negative Prices"
    description: "Create a dataset that includes negative prices to simulate data entry errors or refunds."
    justification: "This rule is designed to reflect real-world scenarios where negative prices may occur due to data entry mistakes or refund processes."
    implementation:
      - "Generate a dataset with positive prices for all entries."
      - "Randomly select a percentage of entries (e.g., 1-5%) to have negative prices."
      - "Change the prices of the selected entries to negative values, ensuring that the negative prices are realistic and reflect common scenarios, such as refunds or discounts."
      - "Ensure that the negative prices are distributed throughout the dataset to simulate real-world occurrences."
      - "Validate the dataset to confirm that the specified percentage of entries have negative prices and that they are correctly represented."